# Email Attachment Intelligence

A production-ready document intelligence pipeline that classifies email attachments from `.eml` files as **relevant** or **irrelevant**, using only the emailâ€™s HTML body context.

This system leverages the Anthropic Claude API for contextual reasoning and includes an evaluation module for performance benchmarking against ground truth data.

---

## ğŸš€ Overview

The project processes `.eml` email files and performs the following:

1. Extracts:
   - HTML body
   - Attachment filenames

2. Classifies each attachment into exactly one category:
   - `relevant`
   - `irrelevant`

3. Generates structured JSON output files.

4. Evaluates predictions against labeled ground truth using standard classification metrics.

---

## ğŸ§  Classification Rules

Classification must rely **exclusively on the emailâ€™s HTML body**.

The following information **must not** be used:
- Attachment contents
- MIME types
- Filenames
- Headers
- Any metadata

This constraint simulates real-world scenarios where reasoning must be based solely on rendered email content.

---

## ğŸ“‚ Project Structure

```text
doczen/
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ example_00001.eml
â”‚   â”œâ”€â”€ example_00002.eml
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ground_truth/
â”‚   â”œâ”€â”€ attachments_00001.json
â”‚   â”œâ”€â”€ attachments_00002.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ output/
â”‚
â”œâ”€â”€ classify_attachments.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/your-org/doczen.git
cd doczen
```

### 2. Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

Example `requirements.txt`:

```
anthropic
beautifulsoup4
tqdm
scikit-learn
```

---

## ğŸ” Environment Configuration

Set your Anthropic API key:

**macOS/Linux**
```bash
export ANTHROPIC_API_KEY=your_key_here
```

**Windows**
```bash
set ANTHROPIC_API_KEY=your_key_here
```

---

# ğŸ“Œ Component 1: Attachment Classification

## Purpose

Reads `.eml` files from `examples/`, extracts HTML content and attachment filenames, and classifies attachments using Claude.

## Run

```bash
python classify_attachments.py
```

## Output

Generated files:

```text
output/
  attachments_00001.json
  attachments_00002.json
  ...
```

Example output:

```json
{
  "relevant": [
    "example_00001_attachment_02.pdf"
  ],
  "irrelevant": [
    "example_00001_attachment_01.jpg"
  ]
}
```

Each attachment must appear in exactly one category.

---

## ğŸ§© Prompt Strategy

The model receives:
- Full HTML body
- List of attachment filenames

It is instructed to:
- Identify attachments materially referenced in the email
- Detect decorative or structural HTML elements (logos, icons, signature images)
- Return strictly structured JSON output
- Avoid explanations

---

# ğŸ“Š Component 2: Evaluation

## Purpose

Compares generated outputs against ground truth labels.

## Run

```bash
python evaluate.py
```

## Metrics Computed

- Accuracy
- Precision
- Recall
- F1 Score
- Per-file breakdown
- Macro-averaged summary

Each attachment is treated as a binary classification:
- Positive â†’ relevant
- Negative â†’ irrelevant

---

## ğŸ“ˆ Evaluation Methodology

Ground truth files must match output naming format:

```text
ground_truth/attachments_00001.json
```

Evaluation compares attachment-level predictions against reference labels.

---

# ğŸ—ï¸ Design Principles

### Deterministic Output
Strict JSON formatting enables automated validation and evaluation.

### Separation of Concerns
- `classify_attachments.py` handles inference
- `evaluate.py` handles benchmarking

### Reproducibility
Consistent file naming and structured outputs ensure experiment tracking.

---

# ğŸ›¡ï¸ Error Handling & Validation

The classification pipeline includes:
- API retry handling
- JSON schema validation
- Attachment coverage verification
- Logging for malformed responses

---

# ğŸ”„ Example Workflow

```bash
# Step 1: Generate classifications
python classify_attachments.py

# Step 2: Evaluate performance
python evaluate.py
```

---

# ğŸš€ Production Considerations

- Rate limiting and exponential backoff
- Deterministic JSON validation
- Cost monitoring for API usage
- Parallel processing support
- Prompt versioning
- CI-based regression evaluation

---

# ğŸ”® Extensibility

This pipeline can be extended to support:

- Confidence scoring
- Multi-class categorization
- Prompt optimization experiments
- Async API batching
- Docker deployment
- Model comparison benchmarking

---

# ğŸ“œ License

MIT License

Copyright (c) 2026 Will
